# ray 集群多机多卡 docker设计/

- 参考
    
    ## 参考
    
    - [使用ray+docker+vllm多机多卡手动部署DeepSeek-R1/V3模型（Linux）_GPU实例最佳实践_最佳实践_弹性云服务器 ECS-华为云](https://support.huaweicloud.com/bestpractice-ecs/ecs_bp_6015.html)
    - [**【ray】 分布式计算的搭建和调用以及项目实践**](https://www.bilibili.com/video/BV1bP41167x7/)
    - 
- 步骤
    
    ```markdown
    
    1.由于需要在docker 镜像内使用本机中的gpu,所以要使用nvidia官方中配置好全套nvidia cuda toolkit等库的镜像
    
    这里展示在普通ubuntu上即使装了cuda版本的pytorch 也显示cuda不可用的情况。
    '''python
    >>> import torch
    >>> print(torch.cuda.is_available())
    False
    >>> print(torch.__version__())
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    TypeError: 'TorchVersion' object is not callable
    >>> print(torch.__version__)
    2.3.1+cu121
    >>> 
    
    1.cuda镜像版本号:https://gitlab.com/nvidia/container-images/cuda/blob/master/doc/unsupported-tags.md
    2.nvidia的docker库:https://hub.docker.com/r/nvidia/cuda
    
    `docker pull nvidia/cuda:12.1.0-cudnn8-devel-ubuntu20.04`
    
    ```
    
- 1.选用镜像
    
    1.选用镜像，这里选择12.1.0-devel-ubuntu20.04
    
    ![image.png](https://wild-firefox.github.io/ray集群多机多卡docker设计/image.png)
    
    ### 核心区别：`base` vs `runtime` vs `devel`
    
    这三个标签决定了镜像中包含了多少 CUDA 工具链的内容，从小到大依次是 `base` < `runtime` < `devel`。
    
    1. **`base` (基础版)**
        - **包含内容**: 只包含运行一个已编译好的 CUDA 程序所需的**最基本**的共享库。这是最精简的版本。
        - **用途**: 用于部署已经编译好的、依赖关系非常简单的 CUDA 应用程序。
        - **特点**: 镜像体积最小。
    2. **`runtime` (运行时版)**
        - **包含内容**: 包含 `base` 的所有内容，**再加上**完整的 CUDA 运行时库（如 `cudart.so`）以及常用的数学库（如 CUBLAS, CUFFT）。
        - **用途**: **最常用**的部署环境。用于运行绝大多数已经编译好的深度学习或科学计算程序（例如，运行一个已经训练好的 PyTorch 模型）。
        - **特点**: 体积适中，功能比 `base` 更全，是部署时的首选。
    3. **`devel` (开发版)**
        - **包含内容**: 包含 `runtime` 的所有内容，**再加上**完整的 CUDA 开发工具包。最关键的是它包含了：
            - **NVCC 编译器**: 用于从源代码编译 CUDA 程序 (`.cu` 文件)。
            - **头文件 (`.h`)**: 编译时需要链接的接口定义。
            - **静态库 (`.a`)**: 静态链接时需要的文件。
            - **调试工具**。
        - **用途**: 用于**编译和开发**。当您需要在 Docker 容器内从源码安装 PyTorch、TensorFlow，或者编译您自己的 C++/CUDA 代码时，必须使用这个版本。
        - **特点**: 镜像体积最大，功能最全。
    
    ---
    
    ### `cudnn` 标签是什么意思？
    
    - **`cudnn`**: 这个标签表示镜像在上述版本的基础上，**额外预装了 NVIDIA cuDNN 库**。
    - **cuDNN (CUDA Deep Neural Network library)** 是一个专门为深度学习框架（如 PyTorch, TensorFlow）优化的 GPU 加速库。
    - **结论**: 如果您要进行深度学习相关的任务，**一定要选择带 `cudnn` 标签的镜像**。
- 当前报错，ray status 状态正常 但是过一会就断了,只剩下一个，从节点状态就dead了
    
    ```markdown
    问题：心跳检测不过
    问题描述：
    1.https://github.com/ray-project/ray/issues/45179
    2.https://discuss.ray.io/t/problems-with-using-ray-in-multiple-dockers/8234
    3.https://github.com/pytorch/pytorch/issues/77523（1.docker wsl2）
    
    参考解决方法：
    1.https://zhuanlan.zhihu.com/p/560731754
    
    https://ray.osanswer.net/t/topic/588
    https://www.cnblogs.com/d37eirin/p/18585884
    https://github.com/ray-project/ray/issues/45179 ##！！
    https://discuss.ray.io/t/worker-gets-killed-unexpectedly/22958/6
    
    需要下载 iptables ufw telnet 
    离线安装：
    库源：
    1.https://packages.ubuntu.com/plucky/arno-iptables-firewall
    或者 2.https://packages.debian.org/bookworm/arno-iptables-firewall
    直接下deb 文件：https://deb.debian.org/debian/pool/main/a/arno-iptables-firewall/
    
    2.https://support.huaweicloud.com/bestpractice-ecs/ecs_bp_6015.html 
    中的这个文件
    https://github.com/vllm-project/vllm/blob/main/examples/online_serving/run_cluster.sh#L87
    这里提到有--network host 的方法
    
    但是 --network=host`模式仅适用于Linux平台，而Docker Desktop for Mac/Windows并不支持该模式。
    见：https://ask.csdn.net/questions/8414615
    ```
    
- 可能方法，报错原因
    
    原因：docker有一层nat，物理机之外连不进去的
    
    [https://blog.51cto.com/u_16099247/6684463](https://blog.51cto.com/u_16099247/6684463)
    
    https://blog.csdn.net/weixin_39059031/article/details/109803742
    
    https://blog.csdn.net/sirobot/article/details/118196012
    
    [Docker 容器使用宿主机同网段IP_docker使用宿主机网段ip-CSDN博客](https://blog.csdn.net/zhangjunli/article/details/103894719)
    
    [Docker 跨主机网络实战：深入 Macvlan，连接容器到物理网络 - Leo-Yide - 博客园](https://www.cnblogs.com/leojazz/p/18815851)
    
- 离网安装工具包
    
    ```markdown
    sudo apt-get install apt-offline
    apt-get install -y python3-apt
    
    ## 创建购物单
    (如果离网的机器上安装 apt-offline了，直接在离网的机器上执行以下命令，如果没有，找一个与离网的机器相同版本的系统的有网的机器，执行以下命令)
    apt-offline set iptables-packages.sig --install-packages iptables
    
    ## 下载所有依赖包
    apt-offline get iptables-packages.sig --bundle iptables-bundle.zip
    
    # 解压 .zip 包
    unzip package_with_deps.zip
    
    备用：
    python3 -m zipfile -e package_with_deps.zip .
    
    # 安装所有 .deb 文件
    sudo dpkg -i *.deb
    
    # 安装单独一个指定deb包
    sudo dpkg -i iptables_1.8.7-1ubuntu5_amd64.deb
    ```
    
- 离网安装python 包
    
    ```markdown
    在现有的有网的机子上
    
    现在，使用 pip wheel 命令。这个命令会查找已安装的 ray 包，并把它和它的所有依赖项都打包成 .whl 文件，存放到你指定的目录中。
    -w 指定存放目录，不使用则放在当前文件地址
    # 语法: pip wheel <包名> -w <存放目录> 
    pip wheel ray -w /tmp/ray_wheels
    
    `注：可以指定版本，若本机conda库没有，则会联网安装`
    
    # 语法: pip install --no-index --find-links=<存放whl文件的目录> <主包名>
    --no-index 禁止网络访问
    pip install --no-index --find-links=~/ray_offline_packages/ ray
    
    # torch 的wheel
    在线下历史版本：
    https://pytorch.org/get-started/previous-versions/
    wheel版本：
    https://download.pytorch.org/whl/torch_stable.html
    https://download.pytorch.org/whl/torch/
    https://download.pytorch.org/whl/torchaudio/
    https://download.pytorch.org/whl/torchvision/
    
    发现直接离线安装pip install "F:\Users\REM\Downloads\torchvision-0.18.1+cu121-cp311-cp311-win_amd64.whl"
    会有问题：
    
    ```python
    Could not fetch URL https://pypi.org/simple/pillow/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pillow/ (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1006)'))) - skipping
    INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.
    ERROR: Could not find a version that satisfies the requirement pillow!=8.3.*,>=5.3.0 (from torchvision) (from versions: none)
    ERROR: No matching distribution found for pillow!=8.3.*,>=5.3.0
    ```
    
    建议直接还是使用wheel的方法安装 ，支持命令`--index-url`
    
    # 离线安装miniconda
    历史版本
    https://repo.anaconda.com/miniconda/
    猜测 此预装3.11.9版本的
    
    conda list -n mybs4 python `查看环境名的python版本`
    
    conda离线创建指定版本python环境：可参考
    https://blog.51cto.com/u_16175439/13057344
    
    ```
    
    ![image.png](https://wild-firefox.github.io/ray集群多机多卡docker设计/image%201.png)
    
- 其他问题及猜测
    
    ```markdown
    ray需要所有的位置都一样吗 
    
    ```
    
- gloo 和nccl 区别
    
    ```markdown
    见：https://zhuanlan.zhihu.com/p/1908266214570041754
    官方torch区别:https://docs.pytorch.ac.cn/docs/stable/distributed.html
    gloo:
     CPU 中心 (CPU-centric by design)：Gloo 最初的设计更多地侧重于 CPU 之间的通信。虽然它可以与 GPU 配合使用（例如，将数据从 GPU 拷贝到 CPU，然后通过 Gloo 通信，再拷贝回 GPU），但其核心优化并非针对 GPU 间的直接高速通信。
    
    issue 问题：
    1.https://github.com/ray-project/ray/issues/42831 （ [W socket.cpp:697] [c10d] The client socket has failed to connect to [kubernetes.docker.internal]:63339 (system error: 10049 ）
    (设置RAY_ENABLE_WINDOWS_OR_OSX_CLUSTER=1 可以使得ray 的集群搭建没问题，但是torch的dist通信有问题（我这里是windows的gloo的后端）)
    2.https://github.com/pytorch/pytorch/issues/80638 （解决上述，我这里反而是使用localhost 在单机多卡不报这个错）
    3.https://github.com/pytorch/pytorch/issues/77523 (可能解决方案：（1.docker wsl2）,尝试连接 苦于没教程 失败 )
    
    多级多卡
    1.https://zhuanlan.zhihu.com/p/373395654（torch的多机多卡 nccl,使用多台机子上分别运行torchrun 训练代码）
    2.https://zhuanlan.zhihu.com/p/618894798 （单机多卡 gloo）
    
    官方torch(多机多卡):
    torchrun:
    https://docs.pytorch.ac.cn/docs/stable/distributed.html#launch-utility
    mp.spawn:
    https://github.com/pytorch/examples/tree/main/imagenet
    
    ray上使用的区别：
    https://github.com/ray-project/ray/blob/master/python/ray/air/tests/test_util_torch_dist.py
    注意：gloo上是 @ray.remote  若有两个gpu则须在函数里显示指定gpu, 一个远程函数给一个gpu，否则只会调用gpu0。
    
    nccl是指定@ray.remote(num_gpus=2) （可尝试 像上述那样指定 应该也可以）
    ```
    
- 总结尝试过程
    
    ```markdown
    目标：在两个局域网下windows主机上使用ray 来实现集群，用ddp 实现多级多卡训练
    
    1.尝试在两个windows上主机 使用docker for windows ,部署docker镜像(nvidia gpu版本ubuntu20.04):
    ray 连通后几秒后断开，心跳检测不过 原因猜测：IP没放开，docker镜像被NAT包住，连不到外面主机
    - 1.尝试使用 docker的部署方法 netmode :host 发现在docker for windows 不支持 部署后镜像1ping不通镜像2
    - 2.尝试使用docker mcvlan的网络方法 发现在docker for windows 不支持 部署后镜像1ping不通镜像2 也找不到类似于ens6f0的以太网名
    2.直接使用windos主机，设置RAY_ENABLE_WINDOWS_OR_OSX_CLUSTER=1 可以使得ray 的集群搭建没问题，但是torch的dist通信有问题（我这里是windows的gloo的后端）
    
    问题描述：
    torch.distributed.init_process_group = init_process_group(backend="gloo", init_method="tcp://localhost:12355")
    torch.distributed.init_process_group = init_process_group(backend="gloo", init_method="tcp://本机ip:12355")
    
    使用local host 不报错，使用本机ip 报下面这个错，将docker关闭也是这个错
    [host.docker.internal]:12355 system error 10049 在其上下文中 ，该地址请求无效
    
    改成127.0.0.1 后 也还是kubernets.docker.internal 参见下图
    
    可以尝试下 ray的train 
    
    可能的解决方案
    https://github.com/pytorch/pytorch/issues/77523（1.docker wsl2）
    ```
    
    ![8516f247cb5872635712fba69455b983.png](https://wild-firefox.github.io/ray集群多机多卡docker设计/8516f247cb5872635712fba69455b983.png)
    
    ```markdown
    `唯一的可试的方法尝试`：
    
    将wsl 设置成一个拥有局域网网段的另外一个ip
    
    如何在WSL2中启用SSH服务，并允许局域网内的其他机器访问WSL2实例？:
    https://juejin.cn/post/7347220605609213987
    
    Windows开启（WSL）Linux子系统并远程连接SSH:
    https://blog.csdn.net/tzsm11/article/details/137093575
    
    如何将 WSL 接入局域网并与宿主机同网段:
    https://blog.csdn.net/song19891121/article/details/138304972
    ```
    
- 官方的部署集群方法
    
    ```markdown
    哪里可以部署集群：
    https://docs.rayai.org.cn/en/latest/cluster/getting-started.html#cluster-index
    
    1.使用Kubernetes 创建集群（官方推荐，适用于大型企业，也可以是本地集群）
    官方教程：https://docs.rayai.org.cn/en/latest/cluster/kubernetes/index.html#kuberay-index
    
    关于：集群环境的初始准备：
    https://docs.rayai.org.cn/en/latest/ray-core/handling-dependencies.html#preparing-an-environment-using-the-ray-cluster-launcher
    
    其他可实践参考：
    基于RayJob(KubeRay)的分布式计算实践：
    https://docs.alayanew.com/docs/documents/bestPractice/distributed/rayJobForDistributedCalc#%E9%83%A8%E7%BD%B2%E5%89%8D%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C
    
    2.使用云服务商平台
    笔记本电脑作为 开发
    云服务商提供ray集群
    
    3.本地集群
    
    ```
    
- 思考：
    
    ```markdown
    在localhost 不报错 (the client has failed to ... )
    在输入windows的ip 报错: host.docker.internal 
    在127.0.0.1 报错:kubernets.docker.internal （这个kubernets正好是集群搭建里用到的，且它默认的master addr地址正好是127.0.0.1）
    
    怀疑：socket.cpp 这个函数 将电脑识别成了一个docker 容器，它想要获取容器外的ip,而这里windows已经是最外层ip了，所以报错
    所以：解决方法 在windows上还得将其放入docker 容器内，让容器内可以ping通其他物理机。
    
    ```
    
- 尝试pytorch 上ddp 多机多卡(双方windows的docker里)
    
    ```markdown
    出现问题：
    https://github.com/NVIDIA/nccl/issues/929
    ```
    
- 终极问题阐述 和 解答思路
    
    ```markdown
    问题描述：（前提条件：启用windows的 【Hyper-V】和【适用于Linux的Windows子系统】）
    windows的shell: ipconfig
    出现 （wsl(Hyper-V firewall)）: 172.26.160.1
    wsl 的shell: ip a
    出现 （eth0）172.26.174.111/20 (类似) 
    wsl的发行版 docker-desktop 里的ubuntu 的shell : ip a
    出现 （eth0）172.21.0.2/16 
    
    在windows 上无解（不适用于torch多机多卡）的原因：(torch的dist问题)
    
    不使用wsl2(docker):
    dist.init_process_group("gloo"): 报错： 
    主机报：
    socket.cpp:697 [host.docker.internal]:12355 system error 10049 在其上下文中 ，该地址请求无效
    从机报：
    socket.cpp:697 [主机名]:12355 system error 10049 在其上下文中 ，该地址请求无效
    
    看着不支持windows，见上述`思考`
    （https://github.com/pytorch/pytorch/issues/77523 ）
    
    使用wsl2(docker)里的ubuntu:
    dist.init_process_group("nccl"):报错：
    从机报:(主机卡住)
    socketStartConnect: Connect to 172.17.0.2<38847>
    
    docker里的ip a 没有局域网网段，
    （无法设置从局域网的网卡 出,即无法设置NCCL_SOCKET_IFNAME=xxx）
    （https://github.com/NVIDIA/nccl/issues/929）
    
    还有唯一的可试的方法：
    (https://github.com/pytorch/pytorch/issues/77523  这里win11 docker的说法，但是不知道怎么搞)
    或者 同样：也是需要将wsl的网段设置成和局域网网段的一个ip,不装docker,在wsl中装ubuntu的发行版
    尝试见上述`总结尝试过程`的`唯一的可试的方法`：
    
    在windows 上无解（不适用于ray多机多卡）的原因:(1.首先是torch的dist问题，2.是ray本身问题)
    
    在windows 上：
    设置RAY_ENABLE_WINDOWS_OR_OSX_CLUSTER=1 可以使用ray 集群
    正常cpu,gpu 都可以使用，但是无法ddp,原因如1
    
    在使用wsl2(docker)里的ubuntu:
    ray 无法通过心跳检测，（双方在docker里的ubuntu的shell 里可以互相ping通对方主机的局域网ip）
    
    ```
    

###